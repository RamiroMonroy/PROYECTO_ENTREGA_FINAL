{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oKsJHqwAO2N"
   },
   "source": [
    "#Proyecto Introduccion a la IA\n",
    "\n",
    "Entrenamiento de la base de datos de Hotel booking demand\n",
    "\n",
    "###Universidad de Antioquia\n",
    "###Facultad de Ingeniería\n",
    "###Ingeniería de Sistemas\n",
    "###UdeA - Ude@\n",
    "###Profesor: Raul Ramos Pollan\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0_RXhPSIsLg"
   },
   "source": [
    "### Integrantes\n",
    "\n",
    "#### Nombre: Ramiro Monroy Ramos\n",
    "\n",
    "#### Cédula: 1027949562\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RS3MlHpqApcr"
   },
   "source": [
    "## Preparación y limpieza de datos. \n",
    "La base de datos utilizada esta compuesta por dos conjuntos de datos; el primero es de el hotel resort (HR)y otro es un hotel urbano(HU). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlHzLyt2BI-z"
   },
   "source": [
    "##Instalación e importación de las librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4KKoYgjgBU77"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "import time\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 119390 entries, 0 to 119389\n",
      "Data columns (total 32 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   hotel                           119390 non-null  object \n",
      " 1   is_canceled                     119390 non-null  int64  \n",
      " 2   lead_time                       119390 non-null  int64  \n",
      " 3   arrival_date_year               119390 non-null  int64  \n",
      " 4   arrival_date_month              119390 non-null  object \n",
      " 5   arrival_date_week_number        119390 non-null  int64  \n",
      " 6   arrival_date_day_of_month       119390 non-null  int64  \n",
      " 7   stays_in_weekend_nights         119390 non-null  int64  \n",
      " 8   stays_in_week_nights            119390 non-null  int64  \n",
      " 9   adults                          119390 non-null  int64  \n",
      " 10  children                        119386 non-null  float64\n",
      " 11  babies                          119390 non-null  int64  \n",
      " 12  meal                            119390 non-null  object \n",
      " 13  country                         118902 non-null  object \n",
      " 14  market_segment                  119390 non-null  object \n",
      " 15  distribution_channel            119390 non-null  object \n",
      " 16  is_repeated_guest               119390 non-null  int64  \n",
      " 17  previous_cancellations          119390 non-null  int64  \n",
      " 18  previous_bookings_not_canceled  119390 non-null  int64  \n",
      " 19  reserved_room_type              119390 non-null  object \n",
      " 20  assigned_room_type              119390 non-null  object \n",
      " 21  booking_changes                 119390 non-null  int64  \n",
      " 22  deposit_type                    119390 non-null  object \n",
      " 23  agent                           103050 non-null  float64\n",
      " 24  company                         6797 non-null    float64\n",
      " 25  days_in_waiting_list            119390 non-null  int64  \n",
      " 26  customer_type                   119390 non-null  object \n",
      " 27  adr                             119390 non-null  float64\n",
      " 28  required_car_parking_spaces     119390 non-null  int64  \n",
      " 29  total_of_special_requests       119390 non-null  int64  \n",
      " 30  reservation_status              119390 non-null  object \n",
      " 31  reservation_status_date         119390 non-null  object \n",
      "dtypes: float64(4), int64(16), object(12)\n",
      "memory usage: 29.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Cargar la base de datos\n",
    "db = pd.read_csv('hotel_bookings.csv')\n",
    "db.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 119390 entries, 0 to 119389\n",
      "Data columns (total 29 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   hotel                           119390 non-null  object \n",
      " 1   is_canceled                     119390 non-null  int64  \n",
      " 2   lead_time                       119390 non-null  int64  \n",
      " 3   arrival_date_year               119390 non-null  int64  \n",
      " 4   arrival_date_month              119390 non-null  object \n",
      " 5   arrival_date_week_number        119390 non-null  int64  \n",
      " 6   arrival_date_day_of_month       119390 non-null  int64  \n",
      " 7   stays_in_weekend_nights         119390 non-null  int64  \n",
      " 8   stays_in_week_nights            119390 non-null  int64  \n",
      " 9   adults                          119390 non-null  int64  \n",
      " 10  children                        119386 non-null  float64\n",
      " 11  babies                          119390 non-null  int64  \n",
      " 12  meal                            119390 non-null  object \n",
      " 13  country                         119390 non-null  object \n",
      " 14  market_segment                  119390 non-null  object \n",
      " 15  distribution_channel            119390 non-null  object \n",
      " 16  is_repeated_guest               119390 non-null  int64  \n",
      " 17  previous_cancellations          119390 non-null  int64  \n",
      " 18  previous_bookings_not_canceled  119390 non-null  int64  \n",
      " 19  reserved_room_type              119390 non-null  object \n",
      " 20  assigned_room_type              119390 non-null  object \n",
      " 21  booking_changes                 119390 non-null  int64  \n",
      " 22  deposit_type                    119390 non-null  object \n",
      " 23  agent                           103050 non-null  float64\n",
      " 24  days_in_waiting_list            119390 non-null  int64  \n",
      " 25  customer_type                   119390 non-null  object \n",
      " 26  adr                             119390 non-null  float64\n",
      " 27  required_car_parking_spaces     119390 non-null  int64  \n",
      " 28  total_of_special_requests       119390 non-null  int64  \n",
      "dtypes: float64(3), int64(16), object(10)\n",
      "memory usage: 26.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#Se limpia country por fuera del pipeline para que no quede agregado en el dataset final como categórico\n",
    "db['country'].fillna(db['country'].mode()[0], inplace=True) \n",
    "# Se eliminan las columnas que no tienen sentido para el entrenamiento\n",
    "# La característica se elimina porque solo existen 6797 valores de el total (119390) lo que corresponde a un porcentaje de faltante del 94.3%\n",
    "# La característica reservation_status se elimina porque es una variable de salida\n",
    "# La característica reservation_status_date se elimina porque es una fecha\n",
    "db = db.drop(columns=['reservation_status', 'reservation_status_date','company'])\n",
    "db.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparación del pipeline para entrenamiento\n",
    "\n",
    "months= ['January','February','March', 'April', 'May', 'June'\n",
    "        ,'July', 'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "\n",
    "def procesar_con_onehotencoder(db):\n",
    "    # Definir los transformadores\n",
    "    #Imputer llena los valores nulos de las características children y agent con un valor 0. Son pocos los valores faltantes.\n",
    "    #Para la característica agent falta un 13% de los datos. Para la característica children falta un 0.003% de los datos.\n",
    "    #OrdinalEncoder le da un valor ordinal a los meses del año que se encuentran en la columna arrival_date_month.\n",
    "    #OneHotEncoder convierte las variables categóricas a numéricas. No hay un orden específico.\n",
    "    transformers = [\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value=0), ['children', 'agent'])\n",
    "        ,('ordinal', OrdinalEncoder(categories=[months]), ['arrival_date_month'])\n",
    "        ,('onehot', OneHotEncoder(sparse_output = False), ['hotel','country', 'meal', 'market_segment', \n",
    "                                                           'distribution_channel','reserved_room_type',\n",
    "                                                           'assigned_room_type','deposit_type','customer_type'])\n",
    "    ]\n",
    "\n",
    "    # Crear el ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(transformers, remainder='passthrough')\n",
    "\n",
    "    # Modelo para entrenamiento\n",
    "    #svc = svm.SVC(decision_function_shape='ovr', kernel='rbf', C = 100, gamma=0.0001)\n",
    "\n",
    "    # Crear el pipeline\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "    # Aplicar el pipeline al DataFrame\n",
    "    transformed_data = pipeline.fit_transform(db)\n",
    "\n",
    "    #transformed_data.shape\n",
    "\n",
    "    # Convertir los resultados en un nuevo DataFrame\n",
    "    #transformed_df = pd.DataFrame(transformed_data)\n",
    "    return transformed_data\n",
    "\n",
    "def procesar_con_ordinalencoder(db):\n",
    "    # Definir los transformadores\n",
    "    #Imputer llena los valores nulos de las características children y agent con un 0. Son pocos los valores faltantes.\n",
    "    #Para la característica agent falta un 13% de los datos. Para la característica children falta un 0.003% de los datos.\n",
    "    #OrdinalEncoder le da un valor ordinal a los meses del año que se encuentran en la columna arrival_date_month.\n",
    "    #LabelEncoder convierte las variables categóricas a numéricas. No hay un orden específico.\n",
    "    transformers = [\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value=0), ['children', 'agent'])\n",
    "        ,('ordinal', OrdinalEncoder(categories=[months]), ['arrival_date_month'])\n",
    "        ,('labelencoder', OrdinalEncoder(), ['hotel','country', 'meal', 'market_segment', \n",
    "                                                           'distribution_channel','reserved_room_type',\n",
    "                                                           'assigned_room_type','deposit_type','customer_type'])\n",
    "    ]\n",
    "\n",
    "    # Crear el ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(transformers, remainder='passthrough')\n",
    "\n",
    "    # Modelo para entrenamiento\n",
    "    #svc = svm.SVC(decision_function_shape='ovr', kernel='rbf', C = 100, gamma=0.0001)\n",
    "\n",
    "    # Crear el pipeline\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "    # Aplicar el pipeline al DataFrame\n",
    "    transformed_data = pipeline.fit_transform(db)\n",
    "\n",
    "    # retornar los resultados\n",
    "    return transformed_data\n",
    "\n",
    "def procesar_con_ordinalencoder_estandarizado(db):\n",
    "    # Definir los transformadores\n",
    "    #Imputer llena los valores nulos de las características children y agent con un 0. Son pocos los valores faltantes.\n",
    "    #Para la característica agent falta un 13% de los datos. Para la característica children falta un 0.003% de los datos.\n",
    "    #OrdinalEncoder le da un valor ordinal a los meses del año que se encuentran en la columna arrival_date_month.\n",
    "    #LabelEncoder convierte las variables categóricas a numéricas. No hay un orden específico.\n",
    "    transformers = [\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value=0), ['children', 'agent'])\n",
    "        ,('ordinal', OrdinalEncoder(categories=[months]), ['arrival_date_month'])\n",
    "        ,('labelencoder', OrdinalEncoder(), ['hotel','country', 'meal', 'market_segment', \n",
    "                                                           'distribution_channel','reserved_room_type',\n",
    "                                                           'assigned_room_type','deposit_type','customer_type'])\n",
    "    ]\n",
    "\n",
    "    # Crear el ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(transformers, remainder='passthrough')\n",
    "\n",
    "    # Modelo para entrenamiento\n",
    "    #svc = svm.SVC(decision_function_shape='ovr', kernel='rbf', C = 100, gamma=0.0001)\n",
    "\n",
    "    # Crear el pipeline\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "    # Aplicar el pipeline al DataFrame\n",
    "    transformed_data = pipeline.fit_transform(db)\n",
    "    \n",
    "    #Aplicar estandarización\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    standardized_data = scaler.fit_transform(transformed_data)\n",
    "    # retornar los resultados\n",
    "    return standardized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119390, 28)\n",
      "(119390,)\n"
     ]
    }
   ],
   "source": [
    "datosX = db.drop('is_canceled', axis=1)\n",
    "\n",
    "Y = np.asarray(db['is_canceled'])\n",
    "X = procesar_con_ordinalencoder_estandarizado(datosX)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.54545455, 1.        , 0.76704545,\n",
       "        0.        , 0.42857143, 0.25      , 0.22222222, 0.18181818,\n",
       "        0.        , 0.66666667, 0.46404342, 0.        , 0.5       ,\n",
       "        0.        , 0.        , 0.        , 0.03636364, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.14285714, 0.        ,\n",
       "        0.00118009, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.54545455, 1.        , 0.76704545,\n",
       "        0.        , 0.42857143, 0.25      , 0.22222222, 0.18181818,\n",
       "        0.        , 0.66666667, 1.        , 0.        , 0.5       ,\n",
       "        0.        , 0.        , 0.        , 0.03636364, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.19047619, 0.        ,\n",
       "        0.00118009, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.54545455, 1.        , 0.33522727,\n",
       "        0.        , 0.42857143, 0.25      , 0.        , 0.18181818,\n",
       "        0.        , 0.66666667, 0.00949796, 0.        , 0.5       ,\n",
       "        0.        , 0.        , 0.02      , 0.01818182, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01505259, 0.        , 0.        ],\n",
       "       [0.        , 0.5682243 , 0.54545455, 1.        , 0.33522727,\n",
       "        0.        , 0.28571429, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.66666667, 0.01763908, 0.        , 0.5       ,\n",
       "        0.        , 0.        , 0.02      , 0.01818182, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01505259, 0.        , 0.        ],\n",
       "       [0.        , 0.44859813, 0.54545455, 1.        , 0.33522727,\n",
       "        0.        , 0.85714286, 0.75      , 0.        , 0.        ,\n",
       "        0.        , 0.66666667, 0.01899593, 0.        , 0.5       ,\n",
       "        0.        , 0.        , 0.04      , 0.03636364, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01930682, 0.        , 0.2       ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Funciones genéricas###\n",
    "\n",
    "def select_features(modelo, n_features, fwd, fltg):\n",
    "    \n",
    "    sfs = SFS(modelo, \n",
    "           k_features=n_features, \n",
    "           forward=fwd,\n",
    "           floating=fltg,\n",
    "           verbose=0,\n",
    "           scoring='accuracy',\n",
    "           cv=0)\n",
    "    \n",
    "    return sfs\n",
    "\n",
    "def classification_error(y_est, y_real):\n",
    "    err = 0\n",
    "    for y_e, y_r in zip(y_est, y_real):\n",
    "\n",
    "        if y_e != y_r:\n",
    "            err += 1\n",
    "\n",
    "    return err/np.size(y_est)\n",
    "\n",
    "\n",
    "def entrenar_con_kfold(clf, X, Y):\n",
    "    errores = np.ones(10)\n",
    "    j = 0\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    #Entrenar el modelo\n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]  \n",
    "\n",
    "        #Aquí se entrena y se valida el modelo sin hacer selección de características\n",
    "\n",
    "        # Entrenamiento el modelo.\n",
    "        model = clf.fit(X_train,y_train)\n",
    "\n",
    "        # Validación del modelo\n",
    "        ypred = model.predict(X_test)\n",
    "\n",
    "        #######\n",
    "\n",
    "        errores[j] = classification_error(ypred, y_test)\n",
    "        j+=1\n",
    "    \n",
    "    return errores\n",
    "    \n",
    "def entrenar_con_stratifiedkfold(clf, X, Y):\n",
    "    errores = np.ones(10)\n",
    "    j = 0\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "    #Entrenar el modelo\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, Y)):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]  \n",
    "\n",
    "        #Aquí se entran y se valida el modelo sin hacer selección de características\n",
    "        # Entrenamiento el modelo.\n",
    "        model = clf.fit(X_train,y_train)\n",
    "\n",
    "        # Validación del modelo\n",
    "        ypred = model.predict(X_test)\n",
    "\n",
    "        errores[j] = classification_error(ypred, y_test)\n",
    "        j+=1\n",
    "    \n",
    "    return errores\n",
    "\n",
    "def entrenar_con_seleccion_kfold(modelo, n_features, fwd, fltg):\n",
    "    errores = np.ones(10)\n",
    "    j = 0\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    #Entrenar el modelo\n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]  \n",
    "\n",
    "        #Aquí se entrena y se valida el modelo sin hacer selección de características\n",
    "\n",
    "        # Entrenamiento el modelo.\n",
    "        sf = select_features(modelo,\n",
    "                        n_features,\n",
    "                        fwd,\n",
    "                        fltg)\n",
    "\n",
    "        # Validación del modelo\n",
    "        sf = sf.fit(X_train, y_train)\n",
    "\n",
    "        #######\n",
    "\n",
    "        errores[j] = 1-sf.k_score_\n",
    "        j+=1\n",
    "    \n",
    "    return errores, sf\n",
    "\n",
    "\n",
    "def entrenar_con_seleccion_stratifiedkfold(modelo, n_features, fwd, fltg):\n",
    "    errores = np.ones(10)\n",
    "    j = 0\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "    #Entrenar el modelo\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, Y)):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]  \n",
    "\n",
    "        #Aquí se entrena y se valida el modelo sin hacer selección de características\n",
    "\n",
    "        # Entrenamiento el modelo.\n",
    "        sf = select_features(modelo,\n",
    "                        n_features,\n",
    "                        fwd,\n",
    "                        fltg)\n",
    "\n",
    "        # Validación del modelo\n",
    "        sf = sf.fit(X_train, y_train)\n",
    "\n",
    "        #######\n",
    "\n",
    "        errores[j] = 1-sf.k_score_\n",
    "        j+=1\n",
    "    \n",
    "    return errores, sf\n",
    "\n",
    "def metrics(y_test, y_pred):\n",
    "  '''\n",
    "  Parametros:\n",
    "    - lista (array) y_test (One-hot encoding)\n",
    "    - lista (array) y_predichas (softmax vector)\n",
    "  Return: \n",
    "    - F1\n",
    "    - Recall\n",
    "    - Precision\n",
    "    - Accuracy\n",
    "    - Especificity\n",
    "  '''\n",
    "  y_test = np.asarray(y_test)\n",
    "  y_pred = np.asarray(y_pred)\n",
    "\n",
    "  if y_test[0].shape[0] == 1:    #Biclase\n",
    "    TP,TN,FP,FN = 0,0,0,0\n",
    "    for t,p in zip(y_test,y_pred):\n",
    "      if t==1:\n",
    "        if p>=0.5: #yp==1:\n",
    "          TP+=1\n",
    "        else:\n",
    "          FN+=1\n",
    "      else:\n",
    "        if p>=0.5: #yp==1:\n",
    "          FP+=1\n",
    "        else:\n",
    "          TN+=1\n",
    "    \n",
    "    recall = TP/(TP+FN)\n",
    "    prec = TP/(TP+FP)\n",
    "    acc = (TP+TN)/(TP+FP+FN+TN)\n",
    "    f1 = (2*recall*prec)/(recall+prec)\n",
    "    esp = TN/(TN+FP)\n",
    "\n",
    "    return f1, recall, prec, acc, esp\n",
    "  \n",
    "  else:    #Multiclase\n",
    "    error = 0\n",
    "    for test,pred in zip(y_test,y_pred):\n",
    "        t = np.argmax(test)\n",
    "        p = np.argmax(pred)\n",
    "        if t!=p:\n",
    "          error+=1\n",
    "          \n",
    "    err = error/np.shape(y_test)[0]     \n",
    "    acc = 1 - err\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM6nF5r5E1yh8hJ3plF4sVg",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
